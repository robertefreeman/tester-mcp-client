version: '3.8'

# Docker Compose configuration for pre-built Docker Hub image
# This file uses the pre-built tester-mcp-client image from Docker Hub
# instead of building from source code.
#
# Usage:
#   1. Copy .env.example to .env and configure your API keys
#   2. Run: docker-compose -f docker-compose.prebuilt.yaml up -d
#   3. Navigate to http://localhost:5001 to access the chat interface

services:
  mcp-client:
    # Use pre-built image from Docker Hub instead of building locally
    image: rfreeman/mcp-test-client:latest
    
    container_name: mcp-test-client
    
    ports:
      - "5001:5001"
    
    environment:
      # Apify API token for MCP server authentication
      - APIFY_TOKEN=${APIFY_TOKEN}
      
      # OpenAI API key for LLM provider access
      - LLM_PROVIDER_API_KEY=${LLM_PROVIDER_API_KEY}
      
      # Custom OpenAI-compatible endpoint (optional)
      - LLM_PROVIDER_BASE_URL=${LLM_PROVIDER_BASE_URL}
      
      # Model name for custom OpenAI-compatible endpoints (optional)
      # Allows runtime override of model name for Ollama, vLLM, local models, etc.
      - MODEL_NAME=${MODEL_NAME}
      
      - ACTOR_WEB_SERVER_PORT=5001
      - NODE_ENV=production
    
    # Health check for service monitoring
    healthcheck:
      test: ["CMD-SHELL", "node -e \"const http = require('http'); const options = { hostname: 'localhost', port: 5001, path: '/client-info', timeout: 5000 }; const req = http.request(options, (res) => { process.exit(res.statusCode === 200 ? 0 : 1); }); req.on('error', () => process.exit(1)); req.on('timeout', () => process.exit(1)); req.end();\""]
      interval: 30s
      timeout: 10s
      start_period: 5s
      retries: 3
    
    restart: unless-stoppedÃŸ